{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0b8c8329a553d3538cac361ce4c3203e268f3f1c81ef0f6be9f0cb77dbc893e63",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "b8c8329a553d3538cac361ce4c3203e268f3f1c81ef0f6be9f0cb77dbc893e63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 51490 entries, 0 to 51489\nData columns (total 61 columns):\n #   Column              Non-Null Count  Dtype\n---  ------              --------------  -----\n 0   gameId              51490 non-null  int64\n 1   creationTime        51490 non-null  int64\n 2   gameDuration        51490 non-null  int64\n 3   seasonId            51490 non-null  int64\n 4   winner              51490 non-null  int64\n 5   firstBlood          51490 non-null  int64\n 6   firstTower          51490 non-null  int64\n 7   firstInhibitor      51490 non-null  int64\n 8   firstBaron          51490 non-null  int64\n 9   firstDragon         51490 non-null  int64\n 10  firstRiftHerald     51490 non-null  int64\n 11  t1_champ1id         51490 non-null  int64\n 12  t1_champ1_sum1      51490 non-null  int64\n 13  t1_champ1_sum2      51490 non-null  int64\n 14  t1_champ2id         51490 non-null  int64\n 15  t1_champ2_sum1      51490 non-null  int64\n 16  t1_champ2_sum2      51490 non-null  int64\n 17  t1_champ3id         51490 non-null  int64\n 18  t1_champ3_sum1      51490 non-null  int64\n 19  t1_champ3_sum2      51490 non-null  int64\n 20  t1_champ4id         51490 non-null  int64\n 21  t1_champ4_sum1      51490 non-null  int64\n 22  t1_champ4_sum2      51490 non-null  int64\n 23  t1_champ5id         51490 non-null  int64\n 24  t1_champ5_sum1      51490 non-null  int64\n 25  t1_champ5_sum2      51490 non-null  int64\n 26  t1_towerKills       51490 non-null  int64\n 27  t1_inhibitorKills   51490 non-null  int64\n 28  t1_baronKills       51490 non-null  int64\n 29  t1_dragonKills      51490 non-null  int64\n 30  t1_riftHeraldKills  51490 non-null  int64\n 31  t1_ban1             51490 non-null  int64\n 32  t1_ban2             51490 non-null  int64\n 33  t1_ban3             51490 non-null  int64\n 34  t1_ban4             51490 non-null  int64\n 35  t1_ban5             51490 non-null  int64\n 36  t2_champ1id         51490 non-null  int64\n 37  t2_champ1_sum1      51490 non-null  int64\n 38  t2_champ1_sum2      51490 non-null  int64\n 39  t2_champ2id         51490 non-null  int64\n 40  t2_champ2_sum1      51490 non-null  int64\n 41  t2_champ2_sum2      51490 non-null  int64\n 42  t2_champ3id         51490 non-null  int64\n 43  t2_champ3_sum1      51490 non-null  int64\n 44  t2_champ3_sum2      51490 non-null  int64\n 45  t2_champ4id         51490 non-null  int64\n 46  t2_champ4_sum1      51490 non-null  int64\n 47  t2_champ4_sum2      51490 non-null  int64\n 48  t2_champ5id         51490 non-null  int64\n 49  t2_champ5_sum1      51490 non-null  int64\n 50  t2_champ5_sum2      51490 non-null  int64\n 51  t2_towerKills       51490 non-null  int64\n 52  t2_inhibitorKills   51490 non-null  int64\n 53  t2_baronKills       51490 non-null  int64\n 54  t2_dragonKills      51490 non-null  int64\n 55  t2_riftHeraldKills  51490 non-null  int64\n 56  t2_ban1             51490 non-null  int64\n 57  t2_ban2             51490 non-null  int64\n 58  t2_ban3             51490 non-null  int64\n 59  t2_ban4             51490 non-null  int64\n 60  t2_ban5             51490 non-null  int64\ndtypes: int64(61)\nmemory usage: 24.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[['winner', 'firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 't1_towerKills', 't1_inhibitorKills', 't1_baronKills', 't1_dragonKills', 't2_towerKills', 't2_inhibitorKills', 't2_baronKills','t2_dragonKills']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(df):\n",
    "  df = df.copy()\n",
    "\n",
    "  # Split the values\n",
    "  y = df['winner']\n",
    "  X = df.drop('winner',axis=1)\n",
    "\n",
    "  # Train test split\n",
    "\n",
    "  X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=62)\n",
    "\n",
    "  # Scale the data\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "\n",
    "  X_train = scaler.transform(X_train)\n",
    "  X_test = scaler.transform(X_test)\n",
    "\n",
    "  return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Support Vector Machine (RBF Kernel) treinado\n",
      "Adaboost treinado\n",
      "Random Forest treinado\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "models = {\n",
    "    'Support Vector Machine (RBF Kernel)': SVC(probability=True),\n",
    "    'Adaboost': AdaBoostClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "for name, model in models.items():\n",
    "  model.fit(X_train,y_train)\n",
    "  print(name + ' treinado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = preprocess_input(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predict Support Vector Machine (RBF Kernel): [[0.5 0.5]]\nPredict Adaboost: [[0.50344495 0.49655505]]\nPredict Random Forest: [[0.51 0.49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
    "\n",
    "scores_list = []\n",
    "\n",
    "for name,model in models.items():\n",
    "  # print(f'Accuracy Score for {name}: {accuracy_score(y_test,model.predict(X_test))}')\n",
    "  # print(f'Precision Score for {name}: {precision_score(y_test,model.predict(X_test))}')\n",
    "  # print(f'Recall Score for {name}: {recall_score(y_test,model.predict(X_test))}')\n",
    "  # print(f'F1 Score for {name}: {f1_score(y_test,model.predict(X_test))}')\n",
    "  # scores_list.append(\n",
    "  #       {\n",
    "  #           'Model': name,\n",
    "  #           'Accuracy': accuracy_score(y_test,model.predict(X_test)),\n",
    "  #           'Precision':  precision_score(y_test,model.predict(X_test)),\n",
    "  #           'Recall': recall_score(y_test,model.predict(X_test)),\n",
    "  #           'F1-Score': f1_score(y_test,model.predict(X_test))\n",
    "  #       }\n",
    "  #   )\n",
    "  \n",
    "  print(f'Predict {name}: {model.predict_proba([[3265584653,1500153862482,2560,9,1,2,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,3,0,0,0,0,0,0]])}')  \n",
    "\n",
    "scores_2 = pd.DataFrame(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                 Model  Accuracy  Precision    Recall  \\\n",
       "0  Support Vector Machine (RBF Kernel)  0.966142   0.966221  0.967083   \n",
       "1                             Adaboost  0.967502   0.964657  0.971549   \n",
       "2                        Random Forest  0.971062   0.969986  0.973080   \n",
       "\n",
       "   F1-Score  \n",
       "0  0.966652  \n",
       "1  0.968091  \n",
       "2  0.971530  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Support Vector Machine (RBF Kernel)</td>\n      <td>0.966142</td>\n      <td>0.966221</td>\n      <td>0.967083</td>\n      <td>0.966652</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adaboost</td>\n      <td>0.967502</td>\n      <td>0.964657</td>\n      <td>0.971549</td>\n      <td>0.968091</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Random Forest</td>\n      <td>0.971062</td>\n      <td>0.969986</td>\n      <td>0.973080</td>\n      <td>0.971530</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}